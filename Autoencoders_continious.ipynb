{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autoencoders_continious.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyM4SE9aP8BM0GMeK6EaksmX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tayfununal/continuous_CNN/blob/main/Autoencoders_continious.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZeRzlR3_Otj"
      },
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "np.random.seed(8)\n",
        "tf.random.set_seed(8)\n",
        "# This is the size of our encoded representations\n",
        "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
        "\n",
        "# This is our input image\n",
        "input_img = keras.Input(shape=(784,))\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "# This model maps an input to its reconstruction\n",
        "autoencoder = keras.Model(input_img, decoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVS5lN1cAKES"
      },
      "source": [
        "# This model maps an input to its encoded representation\n",
        "encoder = keras.Model(input_img, encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdfHCsLFAMtM"
      },
      "source": [
        "# This is our encoded (32-dimensional) input\n",
        "encoded_input = keras.Input(shape=(encoding_dim,))\n",
        "# Retrieve the last layer of the autoencoder model\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "# Create the decoder model\n",
        "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rQs_b--DcIi"
      },
      "source": [
        "lamdas = 1.2\n",
        "batch_size = 60000\n",
        "class CustomMSE(tf.keras.losses.Loss):\n",
        "\n",
        "    def __init__(self, regularization_factor=0.1, name=\"custom_mse\"):\n",
        "        super().__init__(name=name)\n",
        "        self.regularization_factor = regularization_factor\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        # custom cross_entropy = -1/batch_size * tf.reduce_sum(y_true * tf.math.log(y_pred + 10e-15))\n",
        "        binary_entropy_loss = keras.losses.BinaryCrossentropy()(y_true, y_pred)\n",
        "        reg = lamdas * (1/batch_size) * tf.reduce_sum(abs(y_pred - decoder(X_train_with_epsilon)))\n",
        "\n",
        "        return binary_entropy_loss + reg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI9b_cOKAMvc"
      },
      "source": [
        "autoencoder.compile(optimizer='adam', loss=CustomMSE())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV7tvAZbAM2J"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU-pxo8LEBnd"
      },
      "source": [
        "# Adding epsilon\n",
        "tf.random.set_seed(8)\n",
        "epsilon = np.array(tf.random.normal((60000,28,28), mean=0, stddev= 0.00001))\n",
        "\n",
        "epsilon = epsilon.reshape((len(epsilon), np.prod(epsilon.shape[1:])))\n",
        "\n",
        "X_train_with_epsilon = tf.math.add(x_train, epsilon)\n",
        "\n",
        "print('x shape:', X_train_with_epsilon.shape)\n",
        "print('Number of images in x', X_train_with_epsilon.shape[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI9QOYuIAM-O"
      },
      "source": [
        "autoencoder.fit(x_train, X_train_with_epsilon,\n",
        "                epochs=50,\n",
        "                batch_size=60000,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HszWip_ANBA"
      },
      "source": [
        "# Encode and decode some digits\n",
        "# Note that we take them from the *test* set\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "decoded_imgs = decoder.predict(encoded_imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9zduiDQAb1M"
      },
      "source": [
        "# Use Matplotlib (don't ask)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 20  # How many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kg7Efr25Ab56"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLCd4J_uAcJT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
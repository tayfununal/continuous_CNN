{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet50_with_continuous.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP6MLJjB+lwf1joqzkRFe3H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tayfununal/continuous_CNN/blob/main/resnet50_with_continuous.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onO87B41Wv-y"
      },
      "source": [
        "import tensorflow as tf \n",
        "import numpy as np \n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# expand new axis, channel axis \n",
        "x_train = np.expand_dims(x_train, axis=-1)\n",
        "x_test = np.expand_dims(x_test, axis=-1)\n",
        "\n",
        "# [optional]: we may need 3 channel (instead of 1)\n",
        "x_train = np.repeat(x_train, 3, axis=-1)\n",
        "x_test = np.repeat(x_test, 3, axis=-1)\n",
        "\n",
        "# it's always better to normalize \n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# resize the input shape , i.e. old shape: 28, new shape: 32\n",
        "x_train = tf.image.resize(x_train, [32,32]) # if we want to resize \n",
        "x_test = tf.image.resize(x_test, [32,32]) # if we want to resize \n",
        "\n",
        "# one hot \n",
        "y_train = tf.keras.utils.to_categorical(y_train , num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test , num_classes=10)\n",
        "\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R6q0Er5Wzke"
      },
      "source": [
        "np.random.seed(8)\n",
        "tf.random.set_seed(8)\n",
        "\n",
        "input = tf.keras.Input(shape=(32,32,3))\n",
        "efnet = tf.keras.applications.ResNet50(weights='imagenet',\n",
        "                                             include_top = False, \n",
        "                                             input_tensor = input)\n",
        "# Now that we apply global max pooling.\n",
        "gap = tf.keras.layers.GlobalMaxPooling2D()(efnet.output)\n",
        "\n",
        "# Finally, we add a classification layer.\n",
        "output = tf.keras.layers.Dense(10, activation='softmax', use_bias=True)(gap)\n",
        "\n",
        "# bind all\n",
        "func_model = tf.keras.Model(efnet.input, output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc99GP_qXf-u"
      },
      "source": [
        "# Adding epsilon\n",
        "tf.random.set_seed(8)\n",
        "epsilon = tf.random.normal((60000,32,32,3), mean=0, stddev= 0.00001)\n",
        "epsilon_test = tf.random.normal((10000,32, 32,3), mean=0, stddev= 0.00001)\n",
        "\n",
        "X_train_with_epsilon = tf.math.add(x_train, epsilon)\n",
        "X_test_with_epsilon = tf.math.add(x_test, epsilon_test)\n",
        "\n",
        "print('x shape:', X_train_with_epsilon.shape)\n",
        "print('Number of images in x', X_train_with_epsilon.shape[0])\n",
        "print('Number of images in x_t', X_test_with_epsilon.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUn4c4zPW1qN"
      },
      "source": [
        "batch_size = 10000\n",
        "lamdas = 1.2\n",
        "import keras.backend as K\n",
        "class CustomMSE(tf.keras.losses.Loss):\n",
        "\n",
        "    def __init__(self, regularization_factor=0.1, name=\"custom_mse\"):\n",
        "        super().__init__(name=name)\n",
        "        self.regularization_factor = regularization_factor\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        # custom cross_entropy = -1/batch_size * tf.reduce_sum(y_true * tf.math.log(y_pred + 10e-15))\n",
        "        cross_entropy_loss = CategoricalCrossentropy()(y_true, y_pred)\n",
        "        reg = lamdas * (1/batch_size) * tf.reduce_sum(abs(y_pred - func_model(X_train_with_epsilon)))\n",
        "\n",
        "        return cross_entropy_loss + reg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l64-8fgkW1st"
      },
      "source": [
        "func_model.compile(\n",
        "          loss  = CustomMSE(),\n",
        "          metrics = tf.keras.metrics.CategoricalAccuracy(),\n",
        "          optimizer = tf.keras.optimizers.Adam())\n",
        "# fit \n",
        "func_model.fit(x_train, y_train, batch_size=60000, epochs=5, verbose = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRBWedaFW-qO"
      },
      "source": [
        "predictions = func_model.predict(x_test)\n",
        "print(predictions[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywhony2WW_Mt"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(8, 12, figsize=(30, 28))  # 4 = row , 12= column , 30 = horizontal size , 14 = vertical size\n",
        "\n",
        "for i in range(0,8):\n",
        "  for j in range(0,12):\n",
        "    random_int = np.random.randint(1,2000,1)\n",
        "    ax[i][j].imshow(x_test[int(random_int)], cmap=plt.cm.binary)\n",
        "    ax[i][j].set_title(\"Value : {} \\nPredicted Value : {}\".format(int(np.where(y_test[random_int])[1]),np.argmax(predictions[random_int])))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}